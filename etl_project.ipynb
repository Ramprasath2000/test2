{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\ram\\unzipped_data\\source1.csv\n",
      "Processing file: C:\\ram\\unzipped_data\\source1.json\n",
      "Processing file: C:\\ram\\unzipped_data\\source1.xml\n",
      "Processing file: C:\\ram\\unzipped_data\\source2.csv\n",
      "Processing file: C:\\ram\\unzipped_data\\source2.json\n",
      "Processing file: C:\\ram\\unzipped_data\\source2.xml\n",
      "Processing file: C:\\ram\\unzipped_data\\source3.csv\n",
      "Processing file: C:\\ram\\unzipped_data\\source3.json\n",
      "Processing file: C:\\ram\\unzipped_data\\source3.xml\n",
      "Extracted Data:\n",
      "    name height  weight\n",
      "0   alex  65.78  112.99\n",
      "1   ajay  71.52  136.49\n",
      "2  alice   69.4  153.03\n",
      "3   ravi  68.22  142.34\n",
      "4    joe  67.79   144.3\n",
      "Transformed Data:\n",
      "    name    height     weight\n",
      "0   alex  1.670812  51.251360\n",
      "1   ajay  1.816608  61.910772\n",
      "2  alice  1.762760  69.413184\n",
      "3   ravi  1.732788  64.564285\n",
      "4    joe  1.721866  65.453326\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "\n",
    "def log(message, log_file):\n",
    "    \"\"\"Log messages to a log file with a timestamp.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "\n",
    "def unzip_file(zip_path, extract_to):\n",
    "    \"\"\"Unzip the file to the specified directory.\"\"\"\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.makedirs(extract_to)  # Create the folder if it doesn't exist\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "def extract_csv(file_path):\n",
    "    \"\"\"Extract data from a CSV file.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def extract_json(file_path):\n",
    "    \"\"\"Extract data from a JSON file.\"\"\"\n",
    "    try:\n",
    "        return pd.read_json(file_path, lines=True)  # Use lines=True for JSON lines format\n",
    "    except ValueError as e:\n",
    "        print(f\"Error reading JSON file {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def extract_xml(file_path):\n",
    "    \"\"\"Extract data from an XML file.\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        all_data = []\n",
    "        for child in root:\n",
    "            data = {element.tag: element.text for element in child}\n",
    "            all_data.append(data)\n",
    "        return pd.DataFrame(all_data)\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error reading XML file {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def extract_data(data_folder):\n",
    "    \"\"\"Extract data from multiple file formats.\"\"\"\n",
    "    extracted_data = pd.DataFrame()\n",
    "    for file in glob.glob(f\"{data_folder}/*\"):\n",
    "        print(f\"Processing file: {file}\")  # Print each file being processed\n",
    "        try:\n",
    "            if file.endswith('.csv'):\n",
    "                data = extract_csv(file)\n",
    "            elif file.endswith('.json'):\n",
    "                data = extract_json(file)\n",
    "            elif file.endswith('.xml'):\n",
    "                data = extract_xml(file)\n",
    "            else:\n",
    "                continue\n",
    "            extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file}: {e}\")\n",
    "    \n",
    "    # Normalize column names to lowercase for consistency\n",
    "    extracted_data.columns = [col.lower() for col in extracted_data.columns]\n",
    "\n",
    "        # Remove duplicates\n",
    "    extracted_data = extracted_data.drop_duplicates()\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "def transform_data(data):\n",
    "    \"\"\"Transform the data (convert heights and weights).\"\"\"\n",
    "    try:\n",
    "        data['height'] = data['height'].astype(float) * 0.0254  # inches to meters\n",
    "        data['weight'] = data['weight'].astype(float) * 0.453592  # pounds to kilograms\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column during transformation: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Data conversion error during transformation: {e}\")\n",
    "    return data\n",
    "\n",
    "def load_data(data, output_file):\n",
    "    \"\"\"Save the transformed data to a CSV file.\"\"\"\n",
    "    try:\n",
    "        data.to_csv(output_file, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to {output_file}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    zip_file = r'C:\\ram\\source.zip'\n",
    "    data_folder = r'C:\\ram\\unzipped_data'\n",
    "    log_file = r'C:\\ram\\log_file.txt'\n",
    "    output_file = r'C:\\ram\\transformed_data.csv'\n",
    "\n",
    "    # Clear log file\n",
    "    if os.path.exists(log_file):\n",
    "        os.remove(log_file)\n",
    "\n",
    "    # Unzipping step\n",
    "    log(\"Unzipping the file.\", log_file)\n",
    "    unzip_file(zip_file, data_folder)\n",
    "\n",
    "    log(\"ETL process started.\", log_file)\n",
    "    \n",
    "    try:\n",
    "        # Extraction\n",
    "        log(\"Starting data extraction.\", log_file)\n",
    "        extracted_data = extract_data(data_folder)\n",
    "        log(\"Data extraction completed.\", log_file)\n",
    "\n",
    "        # Print extracted data for debugging\n",
    "        print(\"Extracted Data:\")\n",
    "        print(extracted_data.head())\n",
    "\n",
    "        # Transformation\n",
    "        log(\"Starting data transformation.\", log_file)\n",
    "        transformed_data = transform_data(extracted_data)\n",
    "        log(\"Data transformation completed.\", log_file)\n",
    "\n",
    "        # Print transformed data for debugging\n",
    "        print(\"Transformed Data:\")\n",
    "        print(transformed_data.head())\n",
    "\n",
    "        # Loading\n",
    "        log(\"Starting data loading.\", log_file)\n",
    "        load_data(transformed_data, output_file)\n",
    "        log(\"Data loading completed.\", log_file)\n",
    "\n",
    "        log(\"ETL process completed successfully.\", log_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"ETL process failed: {e}\", log_file)\n",
    "        print(f\"ETL process failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
